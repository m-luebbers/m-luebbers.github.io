<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" type="text/css" href="style.css" id="style"/>
	<title> Matthew B. Luebbers </title>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-135111705-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-135111705-1');
	</script>
</head>
<body>
	<div class=wrapper>
		<div class=topblock>
			<div class=topcontent>
				<div id="name">
					<h1> Matthew B. Luebbers </h1>
				</div>

				<div id="menubar">
					<b>
					<a href="#contact">contact</a>
					<a href="#about">about</a>
					<a href="#publications">publications</a>
					<a href="#teaching">teaching</a>
					<a href="https://scholar.google.com/citations?hl=en&user=gc3fI-cAAAAJ" target="_blank">scholar</a>
					<!-- <a href="https://www.linkedin.com/in/matthew-luebbers" target="_blank">linkedin</a> -->
					<a href="pdfs/cv.pdf" target="_blank">CV</a>
					</b>
				</div>

			</div>
		</div>
	</div>
	<div class=centerblock>
		<div class=maintext>
			<div class=mainsection>
				<a class="anchor" name="contact"></a>
				<h2> 
					Contact 
				</h2>
				<p>
					Klaus Advanced Computing Building 1317
					<br />
					Georgia Institute of Technology
					<br />
					Atlanta, Georgia, USA
					<br />
					matthew.luebbers(at)gatech.edu
				</p>
			</div>

			<div class=mainsection>
				<a class="anchor" name="about"></a>
				<div class=lalign>
					<h2> About </h2>
				</div>
				<h3> &nbsp; Personal </h3>

				<p> I'm a postdoctoral fellow in the School of Interactive Computing at the <a href="https://www.gatech.edu/" target="_blank">Georgia Institute of Technology</a>, researching in the <a href="https://core-robotics.gatech.edu/" target="_blank">Cognitive Optimization and Relational (CORE) Robotics Lab</a>, advised by <a href="https://sites.gatech.edu/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</p>

				<p> In 2024, I received my PhD in Computer Science from the <a href="https://www.colorado.edu/" target="_blank">University of Colorado Boulder</a>, where I worked in the <a href="http://www.cairo-lab.com/" target="_blank">Collaborative AI and Robotics (CAIRO) Lab</a>, advised by <a href="http://www.bradhayes.info/" target="_blank">Brad Hayes</a>. Before that, I graduated undergrad from <a href="https://www.cornell.edu/" target="_blank">Cornell University</a> in 2018, where I also majored in Computer Science, specializing in and conducting research into artificial intelligence and robotics in the <a href="https://rpal.cs.cornell.edu/publications/" target="_blank">Robot Personal Assistants Lab (RPAL)</a>.</p>

				<p> Since 2016, I have spent six summers interning at NASA's <a href="https://www.jpl.nasa.gov/" target="_blank">Jet Propulsion Laboratory</a> in Pasadena, California. I have contributed to the Instrument Data Subystem (IDS) and Rover Planning Subystem (RPS) of multiple Martian surface missions - the <a href="https://mars.nasa.gov/msl/" target="_blank">Curiosity</a> rover, the <a href="https://mars.nasa.gov/insight/" target="_blank">InSight</a> lander, and the <a href="https://mars.nasa.gov/mars2020/" target="_blank">Perseverance</a> rover. Throughout my summers working on the RPS team, I have had the incredible opportunity to help drive both Curiosity and Perseverance across five solar-days worth of traverse sequencing, where I have accrued a career Martian odometry of 228 meters (86 m on Curiosity, 142 m on Perseverance)!</p>

				<p> Some of my interests outside of work include observational astronomy, aviation and space travel, traditional animation, language learning, and distance running.</p>
				<!-- <p> Some of my interests outside of work include exploring the natural world, falling down Wikipedia rabbit holes, observational astronomy, aviation and space travel, and traditional animation.</p> -->

				<h3> &nbsp; Research </h3>

				<p>Robotics has traditionally been broken down into two distinct operational paradigms - autonomy and teleoperation. These approaches are inherently limited, however, by the respective weaknesses of autonomous systems and human operators. My research focuses on a third paradigm, where human and robotic agents are treated as teammates working towards a common goal, attempting to leverage each agent's relative strengths to boost the human-robot team's performance beyond the sum of its parts.</p>

				<p>Much like in human teams, demonstrating productive and collaborative behavior in this setup requires plan synchronization (i.e., establishing a <a href="http://www.cairo-lab.com/papers/survey-mental-models.pdf" target="_blank">shared mental model</a>). There's simply too much uncertainty in real world domains to make optimization meaningful without it. However, synchronizing human and robot plans is no easy task - humans and robots plan in fundamentally different ways, making shared reasoning about those plans an exercise in translation. Finding compact ways to facilitate this translation is at the core of my research.</p>

				<p>I develop novel techniques for establishing the shared context between human and robot teammates needed to arrive at suitable multi-agent plans under uncertainty. My work leverages multiple communication modalities, such as augmented reality-based visualization and natural language explanation to underpin well-aligned planners interpretable by both human and robot, improving the fluency, transparency, adaptability, and trustworthiness of human-robot teaming architectures across a variety of task types.</p>

				<!-- <p>Robotics has traditionally been broken down into two distinct operational paradigms – autonomy and teleoperation. These approaches are inherently limited, however, by the respective weaknesses of autonomous systems and human operators. My research therefore focuses on a third paradigm, where human and robotic agents are treated as teammates working towards a common goal, whether the humans and robots are collocated (proximal teaming) or not (remote teaming).</p>

				<p>Much like in human teams, demonstrating productive and collaborative behavior in these setups requires a degree of plan synchronization. Central to achieving this is establishing <a href="http://www.cairo-lab.com/papers/survey-mental-models.pdf" target="_blank">shared mental models</a> between humans and robots – that is, creating formal knowledge structures that allow us to transform between robot planning spaces centered around mathematical optimization, and subjective, variable human planning spaces. This is often a challenging proposition, especially in real world domains with environmental uncertainty and time and safety constraints.</p>

				<p>With this goal in mind, my research involves developing novel techniques for compactly communicating plan rationale and uncertainty to human collaborators through visual, natural language, and behavioral modalities, leveraging emerging technologies like augmented reality and counterfactual explanation to do so. In working to establish shared mental models interpretable by both human and robot, my work aims to improve the fluency, transparency, adaptability, and trust of human-robot teaming architectures across a variety of task types.</p> -->

				<!-- <p> Autonomous systems are steadily becoming more capable, especially through the use of data-driven learned models. Despite the substantial advantages modern autonomy techniques present, they possess some key weaknesses that hinder their deployability in safety-critical systems (such as spacecraft, medical devices, road vehicles, etc.) where they could potentially be most beneficial. Namely, learned models produced through these techniques are inherently uninterpretable by humans, which can lead to unforseen, potentially dangerous failures ultimately attributable to mischaracterization of risk.</p>

				<p> To help address these concerns, I'm interested in creating <b><font color="white">risk-aware shared autonomy</font></b> architectures for robotic task and motion planning, wherein human operator intuition is used to strategically and continuously shape and direct learning-based autonomous controllers. I hypothesize that such hybrid architectures will simulataneously reduce operator workload and add considerable plan flexibility when compared to traditional methods of robot operation, as well as reduce risk and unintended agent behavior when compared to state-of-the-art autonomous approahces.</p>

				<p> This research can be broken down into two primary thrusts, forming two sides of a bi-directional shared autonomy architecture; <b><font color="white">human in the loop planning</font></b> (methods for human operators to efficiently steer and augment optimization-based planners), and <b><font color="white">human interpretable risk assessment</font></b> (improving the situational awareness of operators by algorithmically presenting them with autonomous agents' understanding of sources of plan risk). Underlying both these thrusts is a shared emphasis on effective interface design; allowing operators to inspect model correctness and make informed decisions, while making the most of their cognitive abilities.</p> -->

			</div>

			<div class=mainsection>
				<a class="anchor" name="publications"></a>
				<div class=lalign>
					<h2> Publications </h2>
				</div>
				<p>Asterisk (*) denotes shared first authorship</p>
				<h3> &nbsp; Journal Articles </h3>
				<ul>
					<li>
						Aaquib Tabrez, <b><font color="white">Matthew B. Luebbers</font></b>, and Bradley Hayes. (2020). <q><b>A Survey of Mental Modeling Techniques in Human-Robot Teaming.</b></q> In <i>Current Robotics Reports</i>. Springer-Nature. <b><a href="http://www.cairo-lab.com/papers/survey-mental-models.pdf" target="_blank">Link</a></b>.
					</li>
				</ul>
				<h3> &nbsp; Conference Papers </h3>
				<ul>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>*, Aaquib Tabrez*, Kanaka Samagna Talanki, and Bradley Hayes. (2024). <q><b>Recency Bias in Task Performance History Affects Perceptions of Robot Competence and Trustworthiness.</b></q> In <i>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2024)</i>. Yokohama, Japan. <b><a href="pdfs/icra24.pdf" target="_blank">PDF</a></b>.
						<br>
						<font color="white">Acceptance Rate: 45%.</font>
					</li>
					<li>
						Yi-Shiuan Tung, <b><font color="white">Matthew B. Luebbers</font></b>, Alessandro Roncone, and Bradley Hayes. (2024). <q><b>Workspace Optimization Techniques to Improve Prediction of Human Motion During Human-Robot Collaboration.</b></q> In <i>Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI 2024)</i>. Boulder, Colorado, USA. <b><a href="https://arxiv.org/pdf/2401.12965.pdf" target="_blank">Link</a></b>.
						<br>
						<font color="white"><b>Best Paper Honorable Mention.</b> Acceptance Rate: 25%.</font>
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>*, Aaquib Tabrez*, Kyler Ruvane*, and Bradley Hayes. (2023). <q><b>Autonomous Justification for Enabling Explainable Decision Support in Human-Robot Teaming.</b></q> In <i>Proceedings of Robotics: Science and Systems (RSS 2023)</i>. Daegu, South Korea. <b><a href="pdfs/rss23.pdf" target="_blank">PDF</a></b>.
						<br>
						<font color="white">Acceptance Rate: 31%.</font>
					</li>
					<li>
						Christine T. Chang, <b><font color="white">Matthew B. Luebbers</font></b>, Mitchell Hebert, and Bradley Hayes. (2023). <q><b>Human Non-Compliance with Robot Spatial Ownership Communicated via Augmented Reality: Implications for Human-Robot Teaming Safety.</b></q> In <i>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2023)</i>. London, England, UK. <b><a href="pdfs/icra23.pdf" target="_blank">PDF</a></b>.
						<br>
						<font color="white">Acceptance Rate: 43%.</font>
					</li>
					<li>
						Aaquib Tabrez*, <b><font color="white">Matthew B. Luebbers</font></b>*, and Bradley Hayes. (2022). <q><b>Descriptive and Prescriptive Visual Guidance to Improve Shared Situational Awareness in Human-Robot Teaming.</b></q> In <i>Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2022)</i>. Auckland, New Zealand. <b><a href="pdfs/aamas22.pdf" target="_blank">PDF</a></b>. <b><a href="https://www.youtube.com/watch?v=H0ChHWvfnk8" target="_blank">Video</a></b>.
						<br>
						<font color="white"><b>Best Student Paper Runner-Up (Top 2 of 629 submissions).</b> Acceptance Rate: 26%.</font>
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>, Connor Brooks, Carl L. Mueller, Daniel Szafir, and Bradley Hayes. (2021). <q><b>ARC-LfD: Using Augmented Reality for Interctive Long-Term Robot Skill Maintenance via Constrained Learning from Demonstration.</b></q> In <i>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2021)</i>. Xi'an, China. <b><a href="pdfs/icra21.pdf" target="_blank">PDF</a></b>. <b><a href="https://www.youtube.com/watch?v=KHszZ_YCux4" target="_blank">Video</a></b>.
						<br>
						<font color="white">Acceptance Rate: 48%.</font>
					</li>
				</ul>
				<h3> &nbsp; Workshops, Symposia, &amp; Posters </h3>
				<ul>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b> and Bradley Hayes. (2024). <q><b>Explainable Guidance and Justification for Mental Model Alignment in Human-Robot Teams.</b></q> In <i>Companion for the ACM/IEEE International Conference on Human-Robot Interaction (HRI Pioneers 2024)</i>. Boulder, Colorado, USA. <b><a href="pdfs/hripioneers24.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						 Aaquib Tabrez*, <b><font color="white">Matthew B. Luebbers*</font></b>, Kyler Ruvane*, Ashley H. Rabin, Kevin W. King, William Gerichs, and Bradley Hayes. (2024). <q><b>Hierarchical Multi-Agent Reinforcement Learning with Explainable Decision Support for Human-Robot Teams.</b></q> In <i>Proceedings of the Workshop on Explainability for Human-Robot Collaboration (ExpHRC 2024)</i>. Boulder, Colorado, USA. <b><a href="pdfs/exphrc24.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Yi-Shiuan Tung*, <b><font color="white">Matthew B. Luebbers*</font></b>, Alessandro Roncone, and Bradley Hayes. (2024). <q><b>Stereoscopic Virtual Reality Teleoperation for Human Robot Collaborative Dataset Collection.</b></q> In <i>Proceedings of the Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction (VAM-HRI 2024)</i>. Boulder, Colorado, USA. <b><a href="pdfs/vamhri24.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Maciej K. Wozniak*, Max Pascher*, Bryce Ikeda*, <b><font color="white">Matthew B. Luebbers*</font></b>, and Ayesha Jena*. (2024). <q><b>Virtual, Augmented and Mixed Reality for Human-Robot Interaction</b></q> In <i>Companion for the ACM/IEEE International Conference on Human-Robot Interaction (HRI 2024)</i>. Boulder, Colorado, USA. <b><a href="pdfs/vamproposal24.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Carl L. Mueller, <b><font color="white">Matthew B. Luebbers</font></b>, Aaquib Tabrez, and Bradley Hayes. (2023). <q><b>Augmented Reality and Proxy Grippers Improve Demonstration-based Robot Skill Learning.</b></q> In <i>Proceedings of the Workshop on Life-Long Learning with Human Help (L3H2 2023)</i>. London, England, UK. <b><a href="pdfs/l3h2datatong23.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Breanne Crockett*, Kyler Ruvane*, <b><font color="white">Matthew B. Luebbers</font></b>, and Bradley Hayes. (2023). <q><b>Effective Human-in-the-loop Control Handover via Confidence-Aware Autonomy.</b></q> In <i>Proceedings of the Workshop on Life-Long Learning with Human Help (L3H2 2023)</i>. London, England, UK. <b><a href="pdfs/l3h2handover23.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Yi-Shiuan Tung, <b><font color="white">Matthew B. Luebbers</font></b>, Alessandro Roncone, and Bradley Hayes. (2023). <q><b>Improving Human Legibility in Collaborative Robot Tasks through Augmented Reality and Workspace Preparation.</b></q> In <i>Proceedings of the Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction (VAM-HRI 2023)</i>. Stockholm, Sweden. <b><a href="pdfs/vamhri23.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						Maciej K. Wozniak*, Christine T. Chang*, <b><font color="white">Matthew B. Luebbers</font></b>*, Bryce Ikeda*, Michael E. Walker*, Eric Rosen*, and Thomas Groechel*. (2023). <q><b>Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI).</b></q> In <i>Companion for the ACM/IEEE International Conference on Human-Robot Interaction (HRI 2023)</i>. Stockholm, Sweden. <b><a href="pdfs/vamproposal23.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>*, Aaquib Tabrez*, and Bradley Hayes. (2022). <q><b>Augmented Reality-Based Explainable AI Strategies for Establishing Appropriate Reliance and Trust in Human-Robot Teaming.</b></q> In <i>Proceedings of the Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction (VAM-HRI 2022)</i>. Sapporo, Japan. <b><a href="pdfs/vamhri22.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>*, Christine T. Chang*, Aaquib Tabrez*, Jordan Dixon*, and Bradley Hayes. (2021). <q><b>Emerging Autonomy Solutions for Human and Robotic Deep Space Exploration.</b></q> In <i>Proceedings of SpaceCHI: Human-Computer Interaction for Space Exploration (SpaceCHI 2021)</i>. Yokohama, Japan. <b><a href="pdfs/spacechi21.pdf" target="_blank">PDF</a></b>. <b><a href="pdfs/spacechi21_poster.pdf" target="_blank">Poster</a></b>.
					</li>
					<li>
						Aaquib Tabrez*, <b><font color="white">Matthew B. Luebbers</font></b>*, and Bradley Hayes. (2020). <q><b>Automated Failure-Mode Clustering and Labeling for Informed Car-To-Driver Handover in Autonomous Vehicles.</b></q> In <i>Proceedings of the Workshop on Assessing, Explaining, and Conveying Robot Proficiency for Human-Robot Teaming</i>. Cambridge, England, UK. <b><a href="pdfs/successhri20.pdf" target="_blank">PDF</a></b>. <b><a href="https://www.youtube.com/watch?v=yg8-MGHdDCY&t" target="_blank">Video</a></b>.
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>, Connor Brooks, Minjae John Kim, Daniel Szafir, and Bradley Hayes. (2019). <q><b>Augmented Reality Interface for Constrained Learning from Demonstration.</b></q> In <i> Proceedings of the Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction (VAM-HRI 2019)</i>. Daegu, South Korea. <b><a href="pdfs/vamhri19.pdf" target="_blank">PDF</a></b>.
					</li>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>, Ramchandran Muthukumar, Madeleine Udell, and Ross A. Knepper. (2017). <q><b>Planning Aerial Survey Missions using Low Rank Approximation.</b></q> Presented: <i>Northeast Robotics Colloquium (NERC 2017)</i>. Boston, Massachusetts, USA.
					</li>
				</ul>
				<h3> &nbsp; Thesis </h3>
				<ul>
					<li>
						<b><font color="white">Matthew B. Luebbers</font></b>. (2024). <q><b>Spatially-Grounded Communication for Mental Model Alignment in Human-Robot Teams</b></q> PhD Thesis: <i>University of Colorado Boulder</i>. Boulder, Colorado, USA. <b><a href="pdfs/thesis.pdf" target="_blank">PDF</a></b>.
					</li>
				</ul>
			</div>

			<div class=mainsection>
				<a class="anchor" name="teaching"></a>
				<div class=lalign>
					<h2> Teaching</h2>
				</div>
				<ul class="inline">
					<li> CSCI 5302: Advanced Robotics. <br />
						University of Colorado Boulder, Fall '21. </li>
					<li> CSCI 5722: Computer Vision. <br />
						University of Colorado Boulder, Spring '20. </li>
					<li> CSCI 1300: Introduction to Computer Science. <br />
						University of Colorado Boulder, Fall '19. </li>
					<li> CS 4700: Foundations of Artificial Intelligence. <br />
						Cornell University, Fall '17. </li>
					<li> CS 3410: Computer Systems Organization and Programming. <br />
						Cornell University, Fall '16 - Spring '17. </li>
					<li> CS 2110: Object-Oriented Programming and Data Structures. <br />
						Cornell University, Fall '15 - Spring '16. </li>
				</ul>
				</div>
				</div> <!-- maintext -->
				</div> <!-- centerblock -->
				<div class=bottomblock>
				<div id="copy"> 
					&copy; Matthew B. Luebbers 2024. All rights reserved. 
				</div> 
			</div>
			</body>
			</html>